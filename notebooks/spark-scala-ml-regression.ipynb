{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package ml-regression (org.apache.spark.ml.regression)\n",
    "\n",
    "L'objectif est de faire une présentation de la librairie de régression de Spark ML (Scala).\n",
    "\n",
    "**Note :** Je mets plutôt l'accent sur la démarche et non sur la recherche d'un meilleur modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+----+----+---+----+----+-------+-------+-------+------+----+-----+\n",
      "|      id|maxO3|  T9| T12| T15|Ne9|Ne12|Ne15|    Vx9|   Vx12|   Vx15|maxO3v|vent|pluie|\n",
      "+--------+-----+----+----+----+---+----+----+-------+-------+-------+------+----+-----+\n",
      "|20010601|   87|15.6|18.5|18.4|  4|   4|   8| 0.6946|-1.7101|-0.6946|    84|Nord|  Sec|\n",
      "|20010602|   82|17.0|18.4|17.7|  5|   5|   7|-4.3301|   -4.0|   -3.0|    87|Nord|  Sec|\n",
      "|20010603|   92|15.3|17.6|19.5|  2|   5|   4| 2.9544| 1.8794| 0.5209|    82| Est|  Sec|\n",
      "+--------+-----+----+----+----+---+----+----+-------+-------+-------+------+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\r\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer}\r\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\r\n",
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\r\n",
       "dfmOzone: org.apache.spark.sql.DataFrame = [id: int, maxO3: int ... 12 more fields]\r\n",
       "ventIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_49bbbeb16e27\r\n",
       "pluieIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_07e1c79e214a\r\n",
       "features: Array[String] = Array(T9, T12, T15, Ne9, Ne12, Ne15, Vx9, Vx12, Vx15, maxO3v, ventIndexed, pluieIndexed)\r\n",
       "label: String = maxO3\r\n",
       "predCol: String = maxO3PredictCol\r\n",
       "featureName: String = features\r\n",
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: ui...\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "\n",
    "// Charger les données\n",
    "val dfmOzone = spark.read.option(\"header\",  true)\n",
    "                   .option(\"inferSchema\",  true)\n",
    "                   .option(\"delimiter\", \" \").csv(\"../data/ozone.txt\")\n",
    "dfmOzone.show(3)\n",
    "\n",
    "// Transformer les «strings» en variables catégorielles\n",
    "val ventIndexer= new StringIndexer().setInputCol(\"vent\").setOutputCol(\"ventIndexed\")\n",
    "val pluieIndexer= new StringIndexer().setInputCol(\"pluie\").setOutputCol(\"pluieIndexed\")\n",
    "\n",
    "val features = Array(\"T9\", \"T12\", \"T15\", \"Ne9\", \"Ne12\", \"Ne15\", \"Vx9\", \n",
    "                     \"Vx12\", \"Vx15\", \"maxO3v\", \"ventIndexed\", \"pluieIndexed\")\n",
    "val label = \"maxO3\"\n",
    "val predCol = \"maxO3PredictCol\"\n",
    "val featureName = \"features\"\n",
    "\n",
    "// Assembler les features\n",
    "val assembler = new VectorAssembler().setInputCols(features).setOutputCol(featureName)\n",
    "\n",
    "// Evaluer la performance des modèles avec le RMSE\n",
    "val evaluator = new RegressionEvaluator() \n",
    "                  .setLabelCol(label) \n",
    "                  .setPredictionCol(predCol) \n",
    "                  .setMetricName(\"rmse\")\n",
    "\n",
    "// Séparer les données en train et test\n",
    "val Array(training, test) = dfmOzone.randomSplit(Array(0.8, 0.2), seed = 34512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tests d'algorithmes de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|maxO3|  maxO3PredictCol|\n",
      "+-----+-----------------+\n",
      "|   79|64.43351057025137|\n",
      "|  101| 87.9941163334745|\n",
      "|   57|77.77178041641294|\n",
      "|   71|68.31067713916936|\n",
      "|   56|66.03368854566439|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE = 16.88460042937964"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.LinearRegression\r\n",
       "lr: org.apache.spark.ml.regression.LinearRegression = linReg_0e4699bf5c49\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 50,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.1\r\n",
       "}, {\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 50,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.3\r\n",
       "}, {\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 50,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.7\r\n",
       "}, {\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 100,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.1\r\n",
       "}, {\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 100,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.3\r\n",
       "}, {\r\n",
       "\tlinReg_0e4699bf5c49-maxIter: 100,\r\n",
       "\tlinReg_0e4699bf5c49-regParam: 0.7\r\n",
       "})\r\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_3da9d3a9747b\r\n",
       "trainValidationSplit: org.apache.spark.ml.tuning.TrainValidationSplit = tv...\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "\n",
    "// Regression linéaire\n",
    "val lr = new LinearRegression()\n",
    "            .setLabelCol(label)\n",
    "            .setFeaturesCol(featureName)\n",
    "            .setPredictionCol(predCol)\n",
    "\n",
    "// Grille de recherche pour trouver le meilleur modèle\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(lr.maxIter, Array(50, 100))\n",
    "  .addGrid(lr.regParam,  Array(0.1, 0.3, 0.7))\n",
    "  .build()\n",
    "\n",
    "// Pipeline Préprocessing + Modélisation\n",
    "val pipeline = new Pipeline().setStages(\n",
    "    Array(ventIndexer, pluieIndexer, assembler, lr))\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setTrainRatio(0.8)\n",
    "  .setParallelism(2)\n",
    "\n",
    "// Fitting du modèle\n",
    "val model = pipeline.fit(training)\n",
    "\n",
    "// Prediction en test\n",
    "val predictions = model.transform(test)\n",
    "\n",
    "predictions.select(label, predCol).show(5)\n",
    "\n",
    "// Calcule du RMSE sur le test\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(s\"RMSE = ${rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 20.85954457796239\n",
      "+-----+---------------+\n",
      "|maxO3|maxO3PredictCol|\n",
      "+-----+---------------+\n",
      "|   79|           73.6|\n",
      "|  101|           81.0|\n",
      "|   57|           78.0|\n",
      "|   71|          105.0|\n",
      "|   56|           57.2|\n",
      "|   67|           61.0|\n",
      "+-----+---------------+\n",
      "only showing top 6 rows\n",
      "\n",
      "Regles de prediction :\n",
      " DecisionTreeRegressionModel: uid=dtr_a346119917b6, depth=9, numNodes=47, numFeatures=12\n",
      "  If (feature 0 <= 20.9)\n",
      "   If (feature 9 <= 91.0)\n",
      "    If (feature 4 <= 4.5)\n",
      "     If (feature 10 in {1.0,2.0})\n",
      "      Predict: 81.0\n",
      "     Else (feature 10 not in {1.0,2.0})\n",
      "      Predict: 105.0\n",
      "    Else (feature 4 > 4.5)\n",
      "     If (feature 11 in {1.0})\n",
      "      If (feature 2 <= 21.85)\n",
      "       If (feature 3 <= 7.5)\n",
      "        If (feature 5 <= 3.5)\n",
      "         Predict: 73.0\n",
      "        Else (feature 5 > 3.5)\n",
      "         If (feature 5 <= 7.5)\n",
      "          If (feature 8 <= -4.962)\n",
      "           Predict: 64.5\n",
      "          Else (feature 8 > -4.962)\n",
      "           Predict: 61.0\n",
      "         Else (feature 5 > 7.5)\n",
      "          Predict: 69.33333333333333\n",
      "       Else (feature 3 > 7.5)\n",
      "        Predict: 57.2\n",
      "      Else (feature 2 > 21.85)\n",
      "       Predict: 78.0\n",
      "     Else (feature 11 not in {1.0})\n",
      "      If (feature 3 <= 6.5)\n",
      "       If (feature 6 <= -0.7803)\n",
      "        Predict: 78.4\n",
      "       Else (feature 6 > -0.7803)\n",
      "        Predict: 88.0\n",
      "      Else (feature 3 > 6.5)\n",
      "       If (feature 9 <= 69.0)\n",
      "        Predict: 66.33333333333333\n",
      "       Else (feature 9 > 69.0)\n",
      "        Predict: 73.6\n",
      "   Else (feature 9 > 91.0)\n",
      "    If (feature 2 <= 18.95)\n",
      "     If (feature 1 <= 18.75)\n",
      "      Predict: 77.0\n",
      "     Else (feature 1 > 18.75)\n",
      "      Predict: 83.0\n",
      "    Else (feature 2 > 18.95)\n",
      "     If (feature 6 <= -0.42100000000000004)\n",
      "      If (feature 0 <= 17.65)\n",
      "       If (feature 1 <= 19.5)\n",
      "        Predict: 105.0\n",
      "       Else (feature 1 > 19.5)\n",
      "        Predict: 88.33333333333333\n",
      "      Else (feature 0 > 17.65)\n",
      "       If (feature 1 <= 21.35)\n",
      "        Predict: 74.66666666666667\n",
      "       Else (feature 1 > 21.35)\n",
      "        Predict: 92.0\n",
      "     Else (feature 6 > -0.42100000000000004)\n",
      "      If (feature 4 <= 2.5)\n",
      "       Predict: 111.0\n",
      "      Else (feature 4 > 2.5)\n",
      "       Predict: 96.0\n",
      "  Else (feature 0 > 20.9)\n",
      "   If (feature 9 <= 151.0)\n",
      "    If (feature 4 <= 3.5)\n",
      "     If (feature 9 <= 119.0)\n",
      "      Predict: 125.33333333333333\n",
      "     Else (feature 9 > 119.0)\n",
      "      Predict: 147.5\n",
      "    Else (feature 4 > 3.5)\n",
      "     Predict: 113.75\n",
      "   Else (feature 9 > 151.0)\n",
      "    Predict: 155.66666666666666\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.{DecisionTreeRegressor, DecisionTreeRegressionModel}\r\n",
       "tree: org.apache.spark.ml.regression.DecisionTreeRegressor = dtr_a346119917b6\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\tdtr_a346119917b6-maxDepth: 7,\r\n",
       "\tdtr_a346119917b6-minInstancesPerNode: 3\r\n",
       "}, {\r\n",
       "\tdtr_a346119917b6-maxDepth: 10,\r\n",
       "\tdtr_a346119917b6-minInstancesPerNode: 3\r\n",
       "}, {\r\n",
       "\tdtr_a346119917b6-maxDepth: 7,\r\n",
       "\tdtr_a346119917b6-minInstancesPerNode: 5\r\n",
       "}, {\r\n",
       "\tdtr_a346119917b6-maxDepth: 10,\r\n",
       "\tdtr_a346119917b6-minInstancesPerNode: 5\r\n",
       "})\r\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_58f48336124f\r\n",
       "trainValidationSplit: org.apache.spark.ml.tuning.TrainValidationSplit = tvs_3bd8307310f6\r\n",
       "model: org.apache.spark.ml.tuning.TrainValidationSplitModel = TrainValidationSplitModel...\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.{DecisionTreeRegressor, DecisionTreeRegressionModel}\n",
    "\n",
    "// Arbre de décision\n",
    "val tree = new DecisionTreeRegressor()\n",
    "            .setLabelCol(label)\n",
    "            .setFeaturesCol(featureName)\n",
    "            .setPredictionCol(predCol)\n",
    "\n",
    "// Grille de recherche pour trouver le meilleur modèle\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(tree.maxDepth, Array(7, 10))\n",
    "  .addGrid(tree.minInstancesPerNode, Array(3, 5))\n",
    "  .build()\n",
    "\n",
    "// Pipeline Préprocessing + Modélisation\n",
    "val pipeline = new Pipeline().setStages(\n",
    "    Array(ventIndexer, pluieIndexer, assembler, tree))\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setTrainRatio(0.8)\n",
    "  .setParallelism(2)\n",
    "\n",
    "// Fitting du modèle\n",
    "val model = trainValidationSplit.fit(training)\n",
    "\n",
    "// Prediction en test\n",
    "val predictions = model.transform(test)\n",
    "\n",
    "// Calcule du RMSE sur le test\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(s\"RMSE = ${rmse}\\n\")\n",
    "\n",
    "predictions.select(label, predCol).show(6)\n",
    "\n",
    "// Afficher l'arbre de décision\n",
    "val treeModel = model.bestModel\n",
    "                     .asInstanceOf[PipelineModel]\n",
    "                     .stages\n",
    "                     .last\n",
    "                     .asInstanceOf[DecisionTreeRegressionModel]\n",
    "println(s\"Regles de prediction :\\n ${treeModel.toDebugString}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 16.636849682565877\n",
      "+-----+-----------------+\n",
      "|maxO3|  maxO3PredictCol|\n",
      "+-----+-----------------+\n",
      "|   79|73.41388888888888|\n",
      "|  101|84.87833333333334|\n",
      "|   57|86.22619047619047|\n",
      "|   71|75.96499999999999|\n",
      "|   56| 72.4838888888889|\n",
      "|   67|68.92888888888889|\n",
      "+-----+-----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.RandomForestRegressor\r\n",
       "rf: org.apache.spark.ml.regression.RandomForestRegressor = rfr_e5ab9f043193\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\trfr_e5ab9f043193-featureSubsetStrategy: sqrt,\r\n",
       "\trfr_e5ab9f043193-maxDepth: 7,\r\n",
       "\trfr_e5ab9f043193-minInstancesPerNode: 3,\r\n",
       "\trfr_e5ab9f043193-numTrees: 30,\r\n",
       "\trfr_e5ab9f043193-subsamplingRate: 0.6\r\n",
       "}, {\r\n",
       "\trfr_e5ab9f043193-featureSubsetStrategy: sqrt,\r\n",
       "\trfr_e5ab9f043193-maxDepth: 7,\r\n",
       "\trfr_e5ab9f043193-minInstancesPerNode: 3,\r\n",
       "\trfr_e5ab9f043193-numTrees: 30,\r\n",
       "\trfr_e5ab9f043193-subsamplingRate: 0.8\r\n",
       "}, {\r\n",
       "\trfr_e5ab9f043193-featureSubsetStrategy: log2,\r\n",
       "\trfr_e5ab9f043193-maxDepth: 7,\r\n",
       "\trfr_e5ab9f043193-minInstancesPerNode: 3,\r\n",
       "\trfr_e5ab9f043193-numTrees: 30,\r\n",
       "\trfr_e5ab9f043193-subsamplingRate:...\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "\n",
    "// Random Forest\n",
    "val rf = new RandomForestRegressor()\n",
    "            .setLabelCol(label)\n",
    "            .setFeaturesCol(featureName)\n",
    "            .setPredictionCol(predCol)\n",
    "\n",
    "// Grille de recherche pour trouver le meilleur modèle\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(rf.maxDepth, Array(7, 12))\n",
    "  .addGrid(rf.minInstancesPerNode, Array(3, 5))\n",
    "  .addGrid(rf.numTrees, Array(30, 50))\n",
    "  .addGrid(rf.subsamplingRate, Array(0.6, 0.8))\n",
    "  .addGrid(rf.featureSubsetStrategy, Array(\"sqrt\", \"log2\"))\n",
    "  .build()\n",
    "\n",
    "// Pipeline Préprocessing + Modélisation\n",
    "val pipeline = new Pipeline().setStages(\n",
    "    Array(ventIndexer, pluieIndexer, assembler, rf))\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setTrainRatio(0.8)\n",
    "  .setParallelism(2)\n",
    "\n",
    "// Fitting du modèle\n",
    "val model = trainValidationSplit.fit(training)\n",
    "\n",
    "// Prediction en test\n",
    "val predictions = model.transform(test)\n",
    "\n",
    "// Calcule du RMSE sur le test\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(s\"RMSE = ${rmse}\\n\")\n",
    "\n",
    "predictions.select(label, predCol).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 25.993742739712264\n",
      "+-----+-----------------+\n",
      "|maxO3|  maxO3PredictCol|\n",
      "+-----+-----------------+\n",
      "|   79|75.48334680642589|\n",
      "|  101|82.07077008491203|\n",
      "|   57|72.19845484060436|\n",
      "|   71|71.40835345982528|\n",
      "|   56|53.40715241951024|\n",
      "|   67| 60.1553979926048|\n",
      "+-----+-----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.regression.GBTRegressor\r\n",
       "gbt: org.apache.spark.ml.regression.GBTRegressor = gbtr_b4a185598b7c\r\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\r\n",
       "Array({\r\n",
       "\tgbtr_b4a185598b7c-maxDepth: 5,\r\n",
       "\tgbtr_b4a185598b7c-maxIter: 20,\r\n",
       "\tgbtr_b4a185598b7c-minInstancesPerNode: 3,\r\n",
       "\tgbtr_b4a185598b7c-subsamplingRate: 0.6\r\n",
       "}, {\r\n",
       "\tgbtr_b4a185598b7c-maxDepth: 5,\r\n",
       "\tgbtr_b4a185598b7c-maxIter: 20,\r\n",
       "\tgbtr_b4a185598b7c-minInstancesPerNode: 5,\r\n",
       "\tgbtr_b4a185598b7c-subsamplingRate: 0.6\r\n",
       "}, {\r\n",
       "\tgbtr_b4a185598b7c-maxDepth: 8,\r\n",
       "\tgbtr_b4a185598b7c-maxIter: 20,\r\n",
       "\tgbtr_b4a185598b7c-minInstancesPerNode: 3,\r\n",
       "\tgbtr_b4a185598b7c-subsamplingRate: 0.6\r\n",
       "}, {\r\n",
       "\tgbtr_b4a185598b7c-maxDepth: 8,\r\n",
       "\tgbtr_b4a185598b7c-maxIter: 20,\r\n",
       "\tgbtr_b4a185598b7c-minInstancesPerNode: 5,\r\n",
       "\tgbtr_b4a185598b7c-subsamplin...\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.GBTRegressor\n",
    "\n",
    "// Gradient Boosting Trees\n",
    "val gbt = new GBTRegressor()\n",
    "            .setLabelCol(label)\n",
    "            .setFeaturesCol(featureName)\n",
    "            .setPredictionCol(predCol)\n",
    "\n",
    "// Grille de recherche pour trouver le meilleur modèle\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(gbt.maxDepth, Array(5, 8, 12))\n",
    "  .addGrid(gbt.minInstancesPerNode, Array(3, 5))\n",
    "  .addGrid(gbt.maxIter, Array(20, 30, 50))   \n",
    "  .addGrid(gbt.subsamplingRate, Array(0.6, 0.8))   \n",
    "  .build()\n",
    "\n",
    "// Pipeline Préprocessing + Modélisation\n",
    "val pipeline = new Pipeline().setStages(\n",
    "    Array(ventIndexer, pluieIndexer, assembler, gbt))\n",
    "\n",
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(evaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setTrainRatio(0.8)\n",
    "  .setParallelism(2)\n",
    "\n",
    "// Fitting du modèle\n",
    "val model = trainValidationSplit.fit(training)\n",
    "\n",
    "// Prediction en test\n",
    "val predictions = model.transform(test)\n",
    "\n",
    "// Calcul du RMSE sur le test\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(s\"RMSE = ${rmse}\\n\")\n",
    "\n",
    "predictions.select(label, predCol).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Références :**  \n",
    "[Documentation Spark](https://spark.apache.org/docs/3.0.0/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
